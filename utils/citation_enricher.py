"""
å¼•ç”¨æ•°è¡¥å……å·¥å…·

ä½¿ç”¨Semantic Scholar APIä¸ºè®ºæ–‡è¡¥å……å¼•ç”¨æ•°,ä½†ä¸ç”¨äºæœç´¢
"""
import logging
import time
from typing import List, Optional

try:
    from semanticscholar import SemanticScholar
    HAS_S2 = True
except ImportError:
    HAS_S2 = False

from literature.base_client import PaperMetadata

logger = logging.getLogger(__name__)


class CitationEnricher:
    """
    å¼•ç”¨æ•°è¡¥å……å™¨
    
    ä½¿ç”¨Semantic Scholar APIä¸ºè®ºæ–‡è¡¥å……å¼•ç”¨æ•°,ä½†ä¸ç”¨äºæœç´¢
    è¿™æ ·æ—¢ä¿æŒæœç´¢é€Ÿåº¦å¿«,åˆèƒ½è·å¾—å¼•ç”¨ç»Ÿè®¡
    """
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–
        
        Args:
            api_key: Semantic Scholar APIå¯†é’¥(å¯é€‰,æ— å¯†é’¥æ—¶æœ‰é€Ÿç‡é™åˆ¶)
        """
        if not HAS_S2:
            raise ImportError(
                "éœ€è¦å®‰è£…semanticscholaråŒ…:\n"
                "pip install semanticscholar"
            )
        
        self.s2 = SemanticScholar(api_key=api_key)
        self.api_key = api_key
        
        # é€Ÿç‡é™åˆ¶
        self.request_interval = 0.1 if api_key else 1.0  # æœ‰keyæ—¶æ›´å¿«
        self.last_request_time = 0
        
        logger.info("CitationEnricher initialized")
    
    def enrich_citations(
        self,
        papers: List[PaperMetadata],
        show_progress: bool = True
    ) -> List[PaperMetadata]:
        """
        ä¸ºè®ºæ–‡åˆ—è¡¨è¡¥å……å¼•ç”¨æ•°
        
        Args:
            papers: è®ºæ–‡åˆ—è¡¨
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦
            
        Returns:
            è¡¥å……äº†å¼•ç”¨æ•°çš„è®ºæ–‡åˆ—è¡¨
        """
        if not papers:
            return papers
        
        enriched_count = 0
        failed_count = 0
        
        if show_progress:
            print(f"\nğŸ“Š è¡¥å……å¼•ç”¨æ•°...")
            print(f"  æ€»è®ºæ–‡æ•°: {len(papers)}")
            print(f"  æ­£åœ¨æŸ¥è¯¢Semantic Scholar API...")
        
        for i, paper in enumerate(papers, 1):
            # é€Ÿç‡é™åˆ¶
            self._rate_limit()
            
            # å°è¯•é€šè¿‡ä¸åŒIDæŸ¥è¯¢
            s2_paper = None
            
            # 1. ä¼˜å…ˆç”¨DOI
            if paper.doi and not s2_paper:
                s2_paper = self._get_paper_safe(f"DOI:{paper.doi}")
            
            # 2. å°è¯•arXiv ID
            if paper.arxiv_id and not s2_paper:
                s2_paper = self._get_paper_safe(f"ARXIV:{paper.arxiv_id}")
            
            # 3. å°è¯•PubMed ID
            if paper.pubmed_id and not s2_paper:
                s2_paper = self._get_paper_safe(f"PMID:{paper.pubmed_id}")
            
            # 4. å°è¯•æ ‡é¢˜æœç´¢(æœ€åæ‰‹æ®µ)
            if not s2_paper and paper.title:
                s2_paper = self._search_by_title(paper.title)
            
            # æ›´æ–°å¼•ç”¨æ•°
            if s2_paper:
                paper.citation_count = getattr(s2_paper, 'citationCount', 0) or 0
                enriched_count += 1
                
                # ä¹Ÿå¯ä»¥è¡¥å……å…¶ä»–ä¿¡æ¯
                if not paper.doi and hasattr(s2_paper, 'externalIds'):
                    ext_ids = s2_paper.externalIds or {}
                    if 'DOI' in ext_ids:
                        paper.doi = ext_ids['DOI']
                
                if show_progress and i % 10 == 0:
                    print(f"  è¿›åº¦: {i}/{len(papers)} ({enriched_count}ç¯‡æˆåŠŸ)")
            else:
                failed_count += 1
                paper.citation_count = 0  # æœªæ‰¾åˆ°çš„è®¾ä¸º0
        
        if show_progress:
            print(f"\nâœ“ è¡¥å……å®Œæˆ!")
            print(f"  æˆåŠŸ: {enriched_count}/{len(papers)} ç¯‡")
            print(f"  å¤±è´¥: {failed_count} ç¯‡")
            
            # æ˜¾ç¤ºå¼•ç”¨æ•°ç»Ÿè®¡
            citations = [p.citation_count for p in papers if p.citation_count]
            if citations:
                print(f"\nğŸ“ˆ å¼•ç”¨æ•°ç»Ÿè®¡:")
                print(f"  å¹³å‡: {sum(citations)/len(citations):.1f}")
                print(f"  æœ€é«˜: {max(citations)}")
                print(f"  ä¸­ä½æ•°: {sorted(citations)[len(citations)//2]}")
        
        return papers
    
    def _get_paper_safe(self, paper_id: str) -> Optional[any]:
        """å®‰å…¨åœ°è·å–è®ºæ–‡(å¸¦å¼‚å¸¸å¤„ç†)"""
        try:
            return self.s2.get_paper(paper_id)
        except Exception as e:
            logger.debug(f"Failed to get paper {paper_id}: {e}")
            return None
    
    def _search_by_title(self, title: str) -> Optional[any]:
        """é€šè¿‡æ ‡é¢˜æœç´¢(æœ€åæ‰‹æ®µ)"""
        try:
            results = self.s2.search_paper(title, limit=1)
            if results and len(results) > 0:
                # æ£€æŸ¥æ ‡é¢˜ç›¸ä¼¼åº¦
                result = results[0]
                if hasattr(result, 'title'):
                    # ç®€å•ç›¸ä¼¼åº¦æ£€æŸ¥
                    if title.lower()[:50] in result.title.lower() or result.title.lower()[:50] in title.lower():
                        return result
            return None
        except Exception as e:
            logger.debug(f"Failed to search by title: {e}")
            return None
    
    def _rate_limit(self):
        """é€Ÿç‡é™åˆ¶"""
        current_time = time.time()
        elapsed = current_time - self.last_request_time
        
        if elapsed < self.request_interval:
            time.sleep(self.request_interval - elapsed)
        
        self.last_request_time = time.time()

